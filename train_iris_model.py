#!/usr/bin/env python3
"""
Script para entrenar un modelo simple de clasificaciÃ³n Iris
Este es el "Hello World" del Machine Learning
"""

import numpy as np
import pandas as pd
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import tensorflow as tf
from tensorflow import keras
import pickle
import os
import matplotlib.pyplot as plt
import seaborn as sns

def load_iris_data():
    """Cargar y explorar el dataset Iris"""
    print("ğŸŒ¸ Cargando dataset Iris...")
    
    # Cargar datos
    iris = datasets.load_iris()
    X = iris.data  # caracterÃ­sticas: [sepal_length, sepal_width, petal_length, petal_width]
    y = iris.target  # especies: [0=setosa, 1=versicolor, 2=virginica]
    
    # Nombres de las caracterÃ­sticas y especies
    feature_names = iris.feature_names
    target_names = iris.target_names
    
    print(f"ğŸ“Š Dataset shape: {X.shape}")
    print(f"ğŸ·ï¸  Clases: {target_names}")
    print(f"ğŸ“ CaracterÃ­sticas: {feature_names}")
    
    # Crear DataFrame para mejor visualizaciÃ³n
    df = pd.DataFrame(X, columns=feature_names)
    df['species'] = [target_names[i] for i in y]
    
    print("\nğŸ“‹ Primeras 5 muestras:")
    print(df.head())
    
    print("\nğŸ“ˆ EstadÃ­sticas bÃ¡sicas:")
    print(df.describe())
    
    return X, y, feature_names, target_names, df

def create_visualizations(df, save_path="models/"):
    """Crear visualizaciones del dataset"""
    print("\nğŸ“Š Creando visualizaciones...")
    
    # Configurar estilo
    plt.style.use('seaborn-v0_8')
    
    # 1. DistribuciÃ³n de especies
    plt.figure(figsize=(12, 8))
    
    plt.subplot(2, 2, 1)
    df['species'].value_counts().plot(kind='bar')
    plt.title('DistribuciÃ³n de Especies')
    plt.ylabel('Cantidad')
    
    # 2. Scatter plot: Sepal
    plt.subplot(2, 2, 2)
    for species in df['species'].unique():
        subset = df[df['species'] == species]
        plt.scatter(subset['sepal length (cm)'], subset['sepal width (cm)'], 
                   label=species, alpha=0.7)
    plt.xlabel('Largo del SÃ©palo (cm)')
    plt.ylabel('Ancho del SÃ©palo (cm)')
    plt.title('SÃ©palos por Especie')
    plt.legend()
    
    # 3. Scatter plot: Petal
    plt.subplot(2, 2, 3)
    for species in df['species'].unique():
        subset = df[df['species'] == species]
        plt.scatter(subset['petal length (cm)'], subset['petal width (cm)'], 
                   label=species, alpha=0.7)
    plt.xlabel('Largo del PÃ©talo (cm)')
    plt.ylabel('Ancho del PÃ©talo (cm)')
    plt.title('PÃ©talos por Especie')
    plt.legend()
    
    # 4. Boxplot de todas las caracterÃ­sticas
    plt.subplot(2, 2, 4)
    df_melted = df.melt(id_vars=['species'], var_name='characteristic', value_name='value')
    sns.boxplot(data=df_melted, x='characteristic', y='value', hue='species')
    plt.xticks(rotation=45)
    plt.title('DistribuciÃ³n de CaracterÃ­sticas')
    
    plt.tight_layout()
    plt.savefig(f"{save_path}iris_analysis.png", dpi=300, bbox_inches='tight')
    print(f"ğŸ“Š GrÃ¡ficos guardados en: {save_path}iris_analysis.png")
    plt.close()

def train_sklearn_model(X, y, target_names):
    """Entrenar modelo con scikit-learn"""
    print("\nğŸ”¬ Entrenando modelo con scikit-learn...")
    
    # Dividir datos
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    print(f"ğŸ“Š Datos de entrenamiento: {X_train.shape}")
    print(f"ğŸ“Š Datos de prueba: {X_test.shape}")
    
    # Entrenar modelo Random Forest
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    
    # Predicciones
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    
    print(f"\nâœ… PrecisiÃ³n del modelo: {accuracy:.2%}")
    
    # Reporte detallado
    print("\nğŸ“‹ Reporte de clasificaciÃ³n:")
    print(classification_report(y_test, y_pred, target_names=target_names))
    
    # Matriz de confusiÃ³n
    cm = confusion_matrix(y_test, y_pred)
    print("\nğŸ”¢ Matriz de confusiÃ³n:")
    print(cm)
    
    return model, accuracy

def train_tensorflow_model(X, y, target_names):
    """Entrenar modelo con TensorFlow/Keras para compatibilidad con la API"""
    print("\nğŸ§  Entrenando modelo con TensorFlow...")
    
    # Dividir datos
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    # Normalizar datos
    X_train = X_train.astype('float32')
    X_test = X_test.astype('float32')
    
    # Crear modelo simple de red neuronal
    model = keras.Sequential([
        keras.layers.Dense(16, activation='relu', input_shape=(4,)),
        keras.layers.Dropout(0.2),
        keras.layers.Dense(8, activation='relu'),
        keras.layers.Dense(3, activation='softmax')  # 3 clases
    ])
    
    # Compilar modelo
    model.compile(
        optimizer='adam',
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )
    
    print("ğŸ—ï¸  Arquitectura del modelo:")
    model.summary()
    
    # Entrenar modelo
    print("\nğŸƒâ€â™‚ï¸ Entrenando...")
    history = model.fit(
        X_train, y_train,
        epochs=100,
        batch_size=16,
        validation_split=0.2,
        verbose=0,
        callbacks=[
            keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)
        ]
    )
    
    # Evaluar modelo
    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)
    print(f"\nâœ… PrecisiÃ³n en datos de prueba: {test_accuracy:.2%}")
    
    # Predicciones de ejemplo
    predictions = model.predict(X_test[:5])
    predicted_classes = np.argmax(predictions, axis=1)
    
    print("\nğŸ”® Ejemplos de predicciones:")
    for i in range(5):
        print(f"Muestra {i+1}:")
        print(f"  Real: {target_names[y_test[i]]}")
        print(f"  Predicho: {target_names[predicted_classes[i]]}")
        print(f"  Confianza: {np.max(predictions[i]):.2%}")
        print()
    
    return model, test_accuracy, history

def save_models(sklearn_model, tf_model, save_path="models/"):
    """Guardar ambos modelos"""
    print("\nğŸ’¾ Guardando modelos...")
    
    # Crear directorio si no existe
    os.makedirs(save_path, exist_ok=True)
    
    # Guardar modelo scikit-learn
    with open(f"{save_path}iris_sklearn_model.pkl", 'wb') as f:
        pickle.dump(sklearn_model, f)
    print(f"âœ… Modelo scikit-learn guardado: {save_path}iris_sklearn_model.pkl")
    
    # Guardar modelo TensorFlow (compatible con la API)
    tf_model.save(f"{save_path}iris_classifier.h5")
    print(f"âœ… Modelo TensorFlow guardado: {save_path}iris_classifier.h5")
    
    # Guardar informaciÃ³n del modelo
    model_info = {
        "model_type": "iris_classifier",
        "classes": ["setosa", "versicolor", "virginica"],
        "features": ["sepal_length", "sepal_width", "petal_length", "petal_width"],
        "input_shape": (4,),
        "output_classes": 3,
        "description": "Clasificador de especies de flores Iris"
    }
    
    import json
    with open(f"{save_path}model_info.json", 'w') as f:
        json.dump(model_info, f, indent=2)
    print(f"âœ… InformaciÃ³n del modelo guardada: {save_path}model_info.json")

def create_test_data(save_path="models/"):
    """Crear datos de prueba para la API"""
    print("\nğŸ§ª Creando datos de prueba...")
    
    # Crear algunos ejemplos de datos para probar la API
    test_examples = [
        {
            "name": "setosa_example",
            "data": [5.1, 3.5, 1.4, 0.2],
            "expected_class": 0,
            "expected_name": "setosa"
        },
        {
            "name": "versicolor_example", 
            "data": [6.2, 2.9, 4.3, 1.3],
            "expected_class": 1,
            "expected_name": "versicolor"
        },
        {
            "name": "virginica_example",
            "data": [7.2, 3.0, 5.8, 1.6],
            "expected_class": 2,
            "expected_name": "virginica"
        }
    ]
    
    import json
    with open(f"{save_path}test_examples.json", 'w') as f:
        json.dump(test_examples, f, indent=2)
    print(f"âœ… Ejemplos de prueba guardados: {save_path}test_examples.json")

def main():
    """FunciÃ³n principal"""
    print("ğŸŒ¸ Entrenando el modelo Iris - Hello World del ML!")
    print("="*60)
    
    # Cargar datos
    X, y, feature_names, target_names, df = load_iris_data()
    
    # Crear visualizaciones
    create_visualizations(df)
    
    # Entrenar modelo scikit-learn
    sklearn_model, sklearn_accuracy = train_sklearn_model(X, y, target_names)
    
    # Entrenar modelo TensorFlow
    tf_model, tf_accuracy, history = train_tensorflow_model(X, y, target_names)
    
    # Guardar modelos
    save_models(sklearn_model, tf_model)
    
    # Crear datos de prueba
    create_test_data()
    
    print("\n" + "="*60)
    print("ğŸ‰ Â¡Entrenamiento completado!")
    print(f"ğŸ“Š PrecisiÃ³n scikit-learn: {sklearn_accuracy:.2%}")
    print(f"ğŸ§  PrecisiÃ³n TensorFlow: {tf_accuracy:.2%}")
    print("\nğŸ“‹ Archivos generados:")
    print("  - models/iris_classifier.h5 (modelo para la API)")
    print("  - models/iris_sklearn_model.pkl (modelo scikit-learn)")
    print("  - models/model_info.json (informaciÃ³n del modelo)")
    print("  - models/test_examples.json (ejemplos de prueba)")
    print("  - models/iris_analysis.png (visualizaciones)")
    print("\nğŸš€ Â¡Ya puedes usar la API para hacer predicciones!")

if __name__ == "__main__":
    main()
